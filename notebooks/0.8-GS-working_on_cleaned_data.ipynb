{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd0393438f6c0bca4a2b0b9b28a96f5952f2521bd7399947aa24a0a5b669f83e1d6",
   "display_name": "Python 3.6.12 64-bit ('bigdata': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import CountVectorizer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head, tail = os.path.split(os.getcwd())\n",
    "data_dir = os.path.join(head, 'data')\n",
    "data_raw_dir = os.path.join(data_dir, 'raw')\n",
    "DATA_INTERIM_DIR = os.path.join(data_dir, 'interim')\n",
    "data_raw_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = spark.read.parquet(os.path.join(DATA_INTERIM_DIR, 'cleaned.data'))\n",
    "clean_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.isNull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = clean_data.drop('DATE_ORIGINE','Distance_km','MOTIF_REMORQUAGE','Date_Time','Year', 'Spd_of_Max_Gust')\n",
    "print(features.columns)\n",
    "features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in features.schema.names:\n",
    "    if features.filter(features[col_name].isNull()).count() > 0:\n",
    "        print(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = features.columns, outputCol = 'features')\n",
    "training_df = vectorAssembler.transform(clean_data)\n",
    "training_df = training_df.select(['features', 'Distance_km'])\n",
    "training_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(training_df))\n",
    "train,test = training_df.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol = 'features', labelCol='Distance_km')\n",
    "lr_model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"\\nIntercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainSummary.rootMeanSquaredError)\n",
    "print(\"\\nr2: %f\" % trainSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LinearRegression(featuresCol = 'features', labelCol='Distance_km',maxIter=100, regParam=0.12, elasticNetParam=0.2)\n",
    "lr_model2 = lr.fit(train)\n",
    "print(\"Coefficients: \" + str(lr_model2.coefficients))\n",
    "print(\"\\nIntercept: \" + str(lr_model2.intercept))\n",
    "trainSummary = lr_model2.summary\n",
    "print(\"RMSE: %f\" % trainSummary.rootMeanSquaredError)\n",
    "print(\"\\nr2: %f\" % trainSummary.r2)"
   ]
  },
  {
   "source": [
    "# one-hot encode"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_year = OneHotEncoder(inputCol=\"Year\", outputCol=\"Year_OneHotEncoded\")\n",
    "encoder_month = OneHotEncoder(inputCol=\"Month\", outputCol=\"Month_OneHotEncoded\")\n",
    "encoder_day = OneHotEncoder(inputCol=\"Day\", outputCol=\"Day_OneHotEncoded\")\n",
    "encoder_year.setDropLast(False)\n",
    "encoder_month.setDropLast(False)\n",
    "encoder_day.setDropLast(False)\n",
    "ohe_year = encoder_year.fit(clean_data)\n",
    "ohe_month = encoder_month.fit(clean_data)\n",
    "ohe_day = encoder_day.fit(clean_data)\n",
    "encoded_df = ohe_year.transform(clean_data)\n",
    "encoded_df = ohe_month.transform(encoded_df)\n",
    "encoded_df = ohe_day.transform(encoded_df)\n",
    "encoded_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = ['LONGITUDE_ORIGINE', 'LATITUDE_ORIGINE', 'Mean_Temp', 'Total_Rain', 'Total_Precip', 'Total_Snow', 'Spd_of_Max_Gust', 'Month', 'Day'], outputCol = 'features')\n",
    "training_df = vectorAssembler.transform(clean_data)\n",
    "training_df = training_df.select(['features', 'Distance_km'])\n",
    "training_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = training_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "# validate_df = splits[2]\n",
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol = 'features', labelCol='Distance_km', maxIter=100, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)"
   ]
  },
  {
   "source": [
    "## Convert column to array"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data.withColumn(\"Year_Array\", F.split(F.col(\"Year\"),\" \"))\n",
    "clean_data = clean_data.withColumn(\"Month_Array\", F.split(F.col(\"Month\"),\" \"))\n",
    "clean_data = clean_data.withColumn(\"Day_Array\", F.split(F.col(\"Day\"),\" \"))\n",
    "clean_data.head(2)"
   ]
  },
  {
   "source": [
    "https://www.hackdeploy.com/pyspark-one-hot-encoding-with-countvectorizer/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a CountVectorizer.\n",
    "year_vectorizer = CountVectorizer(inputCol=\"Year_Array\", outputCol=\"Year_OneHotEncoded\", vocabSize=6, minDF=1.0)\n",
    "month_vectorizer = CountVectorizer(inputCol=\"Month_Array\", outputCol=\"Month_OneHotEncoded\", vocabSize=12, minDF=1.0)\n",
    "day_vectorizer = CountVectorizer(inputCol=\"Day_Array\", outputCol=\"Day_OneHotEncoded\", vocabSize=31, minDF=1.0)\n",
    "#Get a VectorizerModel\n",
    "year_vectorizer_model = year_vectorizer.fit(clean_data)\n",
    "month_vectorizer_model = month_vectorizer.fit(clean_data)\n",
    "day_vectorizer_model = day_vectorizer.fit(clean_data)\n",
    "df_ohe = year_vectorizer_model.transform(clean_data)\n",
    "df_ohe = month_vectorizer_model.transform(df_ohe)\n",
    "df_ohe = day_vectorizer_model.transform(df_ohe)\n",
    "df_ohe.head(2)"
   ]
  }
 ]
}